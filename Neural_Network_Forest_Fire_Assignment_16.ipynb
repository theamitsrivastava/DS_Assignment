{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:36:48.824726Z",
     "start_time": "2021-08-10T13:36:27.648160Z"
    },
    "id": "PhgkYKWnm7s3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:37:17.364976Z",
     "start_time": "2021-08-10T13:37:17.226993Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "6xxhEOFmou2u",
    "outputId": "e18e6bfb-2907-4166-d90f-91894f8dd197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/ExcelR/Data Science Assignments/16-Neural Network/forestfires (1).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:37:20.925994Z",
     "start_time": "2021-08-10T13:37:20.846231Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5n80h8Fo9QA",
    "outputId": "25fef670-6fc9-4a20-f64c-dcb2d94120f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:37:59.902200Z",
     "start_time": "2021-08-10T13:37:57.982200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTer7IvBpXUT",
    "outputId": "d9ac3449-536f-4224-f111-eb560076cf47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1= data.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(data1)\n",
    "df_norm = sc.transform(data1)\n",
    "df_norm                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:38:10.641703Z",
     "start_time": "2021-08-10T13:38:10.071938Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oB3ooJ4jpfIu",
    "outputId": "a60f8a2e-e34e-490f-e626-b22b16a0596a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:38:17.074447Z",
     "start_time": "2021-08-10T13:38:17.055149Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFCGP9SapmGs",
    "outputId": "040e0c0e-e2d1-4aed-ff8d-1cb24a45d18f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of variance that each PCA explains is \n",
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:38:18.152836Z",
     "start_time": "2021-08-10T13:38:18.117784Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzUYVrxpps8_",
    "outputId": "44d247f0-d39b-4e4a-f044-65bb6cbe3536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative variance \n",
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "soIeXHtvpzIA",
    "outputId": "c30e6bcd-a2f7-494c-fd84-5e8b19c8107a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variance plot for PCA components obtained\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:38:41.820961Z",
     "start_time": "2021-08-10T13:38:41.703707Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "AJEQ1Mm5p4Bm",
    "outputId": "abe85361-7476-4a9d-e3b2-7302137d2438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting first 24 PCA out of 28\n",
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     data[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:38:43.982268Z",
     "start_time": "2021-08-10T13:38:43.940388Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVjkreCPqJep",
    "outputId": "889cb4b4-389d-4ad9-8ff2-8b706359afd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7PTif6NqcTC"
   },
   "source": [
    "**Iteration 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:46:14.916350Z",
     "start_time": "2021-08-10T13:45:44.853929Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EnnGcQ9rxw2",
    "outputId": "13fe86fb-40c6-42ac-b367-819175ee7864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.7507 - val_loss: 0.7322 - val_accuracy: 0.6667\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7562 - val_loss: 0.7215 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7562 - val_loss: 0.7086 - val_accuracy: 0.6731\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7562 - val_loss: 0.6947 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7562 - val_loss: 0.6936 - val_accuracy: 0.6731\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7562 - val_loss: 0.6906 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7562 - val_loss: 0.6935 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7590 - val_loss: 0.6965 - val_accuracy: 0.6795\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7590 - val_loss: 0.6936 - val_accuracy: 0.6795\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7756 - val_loss: 0.6946 - val_accuracy: 0.6731\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7812 - val_loss: 0.6940 - val_accuracy: 0.6731\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7839 - val_loss: 0.6881 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7922 - val_loss: 0.6839 - val_accuracy: 0.6731\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7895 - val_loss: 0.6946 - val_accuracy: 0.6731\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7895 - val_loss: 0.7038 - val_accuracy: 0.6731\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7978 - val_loss: 0.6871 - val_accuracy: 0.6731\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8006 - val_loss: 0.6951 - val_accuracy: 0.6667\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.8006 - val_loss: 0.6887 - val_accuracy: 0.6795\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8006 - val_loss: 0.6915 - val_accuracy: 0.6795\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.8006 - val_loss: 0.7029 - val_accuracy: 0.6795\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7978 - val_loss: 0.6838 - val_accuracy: 0.6795\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8006 - val_loss: 0.6936 - val_accuracy: 0.6795\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8089 - val_loss: 0.6813 - val_accuracy: 0.6795\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8089 - val_loss: 0.6904 - val_accuracy: 0.6795\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8061 - val_loss: 0.6930 - val_accuracy: 0.6795\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8089 - val_loss: 0.6886 - val_accuracy: 0.6859\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8089 - val_loss: 0.6962 - val_accuracy: 0.6859\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8144 - val_loss: 0.6824 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8144 - val_loss: 0.6843 - val_accuracy: 0.6731\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8172 - val_loss: 0.6849 - val_accuracy: 0.6731\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8172 - val_loss: 0.6917 - val_accuracy: 0.6795\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8172 - val_loss: 0.6860 - val_accuracy: 0.6795\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8283 - val_loss: 0.6867 - val_accuracy: 0.6795\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8227 - val_loss: 0.6899 - val_accuracy: 0.6859\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8393 - val_loss: 0.6758 - val_accuracy: 0.6859\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8421 - val_loss: 0.6851 - val_accuracy: 0.6859\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8421 - val_loss: 0.6857 - val_accuracy: 0.6987\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8421 - val_loss: 0.6844 - val_accuracy: 0.6923\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8421 - val_loss: 0.6858 - val_accuracy: 0.7115\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8338 - val_loss: 0.6904 - val_accuracy: 0.7179\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8504 - val_loss: 0.6917 - val_accuracy: 0.7115\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8421 - val_loss: 0.6935 - val_accuracy: 0.7115\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8504 - val_loss: 0.6888 - val_accuracy: 0.7179\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8532 - val_loss: 0.6852 - val_accuracy: 0.7179\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8560 - val_loss: 0.6905 - val_accuracy: 0.7115\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8587 - val_loss: 0.6983 - val_accuracy: 0.7115\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8587 - val_loss: 0.6988 - val_accuracy: 0.7115\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8587 - val_loss: 0.6998 - val_accuracy: 0.7115\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8615 - val_loss: 0.7073 - val_accuracy: 0.7115\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8670 - val_loss: 0.6999 - val_accuracy: 0.7244\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8726 - val_loss: 0.6863 - val_accuracy: 0.7372\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8615 - val_loss: 0.7008 - val_accuracy: 0.7436\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8781 - val_loss: 0.7053 - val_accuracy: 0.7436\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8892 - val_loss: 0.7113 - val_accuracy: 0.7436\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.8809 - val_loss: 0.7212 - val_accuracy: 0.7436\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9003 - val_loss: 0.7271 - val_accuracy: 0.7500\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2591 - accuracy: 0.8920 - val_loss: 0.7303 - val_accuracy: 0.7436\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2541 - accuracy: 0.9086 - val_loss: 0.7315 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2491 - accuracy: 0.9030 - val_loss: 0.7444 - val_accuracy: 0.7500\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.9086 - val_loss: 0.7383 - val_accuracy: 0.7436\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9169 - val_loss: 0.7429 - val_accuracy: 0.7436\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9197 - val_loss: 0.7475 - val_accuracy: 0.7436\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2297 - accuracy: 0.9197 - val_loss: 0.7460 - val_accuracy: 0.7500\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9197 - val_loss: 0.7590 - val_accuracy: 0.7500\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9224 - val_loss: 0.7609 - val_accuracy: 0.7564\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9335 - val_loss: 0.7616 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2097 - accuracy: 0.9280 - val_loss: 0.7673 - val_accuracy: 0.7628\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9307 - val_loss: 0.7681 - val_accuracy: 0.7628\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9335 - val_loss: 0.7736 - val_accuracy: 0.7628\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 0.9252 - val_loss: 0.7753 - val_accuracy: 0.7500\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9335 - val_loss: 0.7854 - val_accuracy: 0.7628\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.9363 - val_loss: 0.7776 - val_accuracy: 0.7564\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.9335 - val_loss: 0.7867 - val_accuracy: 0.7500\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9307 - val_loss: 0.7921 - val_accuracy: 0.7628\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1771 - accuracy: 0.9446 - val_loss: 0.7847 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1812 - accuracy: 0.9529 - val_loss: 0.7774 - val_accuracy: 0.7500\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1738 - accuracy: 0.9418 - val_loss: 0.7872 - val_accuracy: 0.7564\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1698 - accuracy: 0.9446 - val_loss: 0.8013 - val_accuracy: 0.7500\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1635 - accuracy: 0.9418 - val_loss: 0.8056 - val_accuracy: 0.7564\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 0.9418 - val_loss: 0.8007 - val_accuracy: 0.7372\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9529 - val_loss: 0.8192 - val_accuracy: 0.7436\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9501 - val_loss: 0.8230 - val_accuracy: 0.7308\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1541 - accuracy: 0.9501 - val_loss: 0.8247 - val_accuracy: 0.7372\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9418 - val_loss: 0.8321 - val_accuracy: 0.7564\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9501 - val_loss: 0.8422 - val_accuracy: 0.7308\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1457 - accuracy: 0.9474 - val_loss: 0.8509 - val_accuracy: 0.7372\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9529 - val_loss: 0.8596 - val_accuracy: 0.7564\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1431 - accuracy: 0.9557 - val_loss: 0.8589 - val_accuracy: 0.7436\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.9557 - val_loss: 0.8678 - val_accuracy: 0.7436\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9557 - val_loss: 0.8795 - val_accuracy: 0.7500\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9529 - val_loss: 0.8812 - val_accuracy: 0.7564\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9557 - val_loss: 0.8900 - val_accuracy: 0.7564\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9612 - val_loss: 0.8872 - val_accuracy: 0.7564\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9557 - val_loss: 0.8910 - val_accuracy: 0.7500\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9557 - val_loss: 0.9060 - val_accuracy: 0.7500\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.9612 - val_loss: 0.9226 - val_accuracy: 0.7500\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.9584 - val_loss: 0.9451 - val_accuracy: 0.7564\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9584 - val_loss: 0.9360 - val_accuracy: 0.7628\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9584 - val_loss: 0.9634 - val_accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9584 - val_loss: 0.9538 - val_accuracy: 0.7500\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9640 - val_loss: 0.9574 - val_accuracy: 0.7564\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9640 - val_loss: 0.9718 - val_accuracy: 0.7500\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9668 - val_loss: 0.9715 - val_accuracy: 0.7372\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9668 - val_loss: 0.9884 - val_accuracy: 0.7436\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.9695 - val_loss: 0.9896 - val_accuracy: 0.7436\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.9869 - val_accuracy: 0.7436\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9695 - val_loss: 0.9914 - val_accuracy: 0.7500\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9723 - val_loss: 1.0109 - val_accuracy: 0.7436\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9695 - val_loss: 1.0207 - val_accuracy: 0.7436\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9612 - val_loss: 1.0199 - val_accuracy: 0.7436\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9723 - val_loss: 1.0265 - val_accuracy: 0.7436\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9668 - val_loss: 1.0352 - val_accuracy: 0.7436\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9695 - val_loss: 1.0523 - val_accuracy: 0.7436\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9668 - val_loss: 1.0470 - val_accuracy: 0.7372\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 1.0603 - val_accuracy: 0.7436\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9723 - val_loss: 1.0597 - val_accuracy: 0.7372\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9751 - val_loss: 1.0856 - val_accuracy: 0.7372\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9668 - val_loss: 1.0824 - val_accuracy: 0.7372\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9723 - val_loss: 1.0888 - val_accuracy: 0.7436\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9695 - val_loss: 1.0778 - val_accuracy: 0.7564\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9695 - val_loss: 1.0971 - val_accuracy: 0.7436\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9778 - val_loss: 1.1045 - val_accuracy: 0.7308\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9778 - val_loss: 1.1098 - val_accuracy: 0.7500\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 1.1509 - val_accuracy: 0.7436\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9806 - val_loss: 1.1458 - val_accuracy: 0.7564\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9723 - val_loss: 1.1200 - val_accuracy: 0.7564\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9806 - val_loss: 1.1201 - val_accuracy: 0.7436\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9751 - val_loss: 1.1356 - val_accuracy: 0.7436\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9861 - val_loss: 1.1423 - val_accuracy: 0.7436\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9751 - val_loss: 1.1359 - val_accuracy: 0.7436\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9834 - val_loss: 1.1446 - val_accuracy: 0.7372\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9778 - val_loss: 1.1658 - val_accuracy: 0.7372\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9889 - val_loss: 1.1835 - val_accuracy: 0.7564\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9834 - val_loss: 1.1760 - val_accuracy: 0.7436\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9889 - val_loss: 1.1924 - val_accuracy: 0.7308\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9945 - val_loss: 1.1912 - val_accuracy: 0.7372\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9917 - val_loss: 1.1972 - val_accuracy: 0.7372\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9917 - val_loss: 1.1999 - val_accuracy: 0.7308\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9889 - val_loss: 1.2133 - val_accuracy: 0.7244\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.7436\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9945 - val_loss: 1.2162 - val_accuracy: 0.7372\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9945 - val_loss: 1.2245 - val_accuracy: 0.7500\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9945 - val_loss: 1.2294 - val_accuracy: 0.7372\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9972 - val_loss: 1.2380 - val_accuracy: 0.7500\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9945 - val_loss: 1.2371 - val_accuracy: 0.7372\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 1.2591 - val_accuracy: 0.7372\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9972 - val_loss: 1.2679 - val_accuracy: 0.7308\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9945 - val_loss: 1.2711 - val_accuracy: 0.7436\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9972 - val_loss: 1.2928 - val_accuracy: 0.7372\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9917 - val_loss: 1.2651 - val_accuracy: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253f6411688>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:46:15.269405Z",
     "start_time": "2021-08-10T13:46:14.924682Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQweyXPzsAGo",
    "outputId": "cda7009c-6b33-4b5e-b1dc-944c7729a3ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.9188\n",
      "accuracy: 91.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kqJLBSzq1g1"
   },
   "source": [
    "**Iteration 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:40:44.891788Z",
     "start_time": "2021-08-10T13:40:27.857386Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gA9M1pjTrUWn",
    "outputId": "d10b6af3-0ae5-4ebc-9f0c-aad83eb7cdab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 3.3752 - accuracy: 0.7562 - val_loss: 3.6944 - val_accuracy: 0.6731\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0623 - accuracy: 0.7562 - val_loss: 1.4084 - val_accuracy: 0.6731\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.1839 - accuracy: 0.7562 - val_loss: 0.9770 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7095 - accuracy: 0.7590 - val_loss: 0.9073 - val_accuracy: 0.6795\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5768 - accuracy: 0.7590 - val_loss: 0.9003 - val_accuracy: 0.6795\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5681 - accuracy: 0.7590 - val_loss: 0.8311 - val_accuracy: 0.6731\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5648 - accuracy: 0.7590 - val_loss: 0.7269 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7590 - val_loss: 0.8350 - val_accuracy: 0.6795\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7590 - val_loss: 0.8349 - val_accuracy: 0.6795\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7590 - val_loss: 0.8365 - val_accuracy: 0.6795\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5516 - accuracy: 0.7590 - val_loss: 0.6961 - val_accuracy: 0.6795\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7590 - val_loss: 0.6783 - val_accuracy: 0.6795\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.7590 - val_loss: 0.7008 - val_accuracy: 0.6795\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5440 - accuracy: 0.7590 - val_loss: 0.7088 - val_accuracy: 0.6795\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.7590 - val_loss: 0.7716 - val_accuracy: 0.6795\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7590 - val_loss: 0.6876 - val_accuracy: 0.6795\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7590 - val_loss: 0.7632 - val_accuracy: 0.6795\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7590 - val_loss: 0.6778 - val_accuracy: 0.6795\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7590 - val_loss: 0.6922 - val_accuracy: 0.6795\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7590 - val_loss: 0.7667 - val_accuracy: 0.6795\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.7590 - val_loss: 0.7904 - val_accuracy: 0.6795\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.7590 - val_loss: 0.7761 - val_accuracy: 0.6795\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.7590 - val_loss: 0.7717 - val_accuracy: 0.6795\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.7590 - val_loss: 0.7679 - val_accuracy: 0.6795\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.7590 - val_loss: 0.7718 - val_accuracy: 0.6795\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5089 - accuracy: 0.7590 - val_loss: 0.7726 - val_accuracy: 0.6795\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5063 - accuracy: 0.7590 - val_loss: 0.7732 - val_accuracy: 0.6795\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5059 - accuracy: 0.7590 - val_loss: 0.6999 - val_accuracy: 0.6795\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.7590 - val_loss: 0.7742 - val_accuracy: 0.6795\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.7590 - val_loss: 0.8033 - val_accuracy: 0.6795\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4961 - accuracy: 0.7618 - val_loss: 0.7914 - val_accuracy: 0.6795\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4935 - accuracy: 0.7590 - val_loss: 0.8514 - val_accuracy: 0.6795\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7618 - val_loss: 0.6811 - val_accuracy: 0.6795\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7756 - val_loss: 0.6814 - val_accuracy: 0.6795\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7729 - val_loss: 0.7893 - val_accuracy: 0.6795\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7701 - val_loss: 0.8529 - val_accuracy: 0.6795\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7729 - val_loss: 0.8520 - val_accuracy: 0.6795\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7729 - val_loss: 0.8802 - val_accuracy: 0.6795\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.7550 - val_accuracy: 0.6923\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7867 - val_loss: 0.7803 - val_accuracy: 0.6923\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7839 - val_loss: 0.8391 - val_accuracy: 0.6923\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7867 - val_loss: 1.0029 - val_accuracy: 0.6923\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7867 - val_loss: 1.0089 - val_accuracy: 0.6923\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7867 - val_loss: 1.0072 - val_accuracy: 0.6923\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7867 - val_loss: 1.0156 - val_accuracy: 0.6923\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7895 - val_loss: 1.0793 - val_accuracy: 0.6923\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7895 - val_loss: 0.9484 - val_accuracy: 0.6923\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7867 - val_loss: 1.0702 - val_accuracy: 0.6923\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7867 - val_loss: 1.0680 - val_accuracy: 0.6923\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7922 - val_loss: 0.9087 - val_accuracy: 0.6987\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4460 - accuracy: 0.7922 - val_loss: 0.9949 - val_accuracy: 0.6987\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.7922 - val_loss: 0.9919 - val_accuracy: 0.6987\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7922 - val_loss: 0.9703 - val_accuracy: 0.6987\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.7922 - val_loss: 0.9769 - val_accuracy: 0.6987\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7922 - val_loss: 0.9758 - val_accuracy: 0.6987\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7922 - val_loss: 0.9819 - val_accuracy: 0.7051\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7922 - val_loss: 0.9813 - val_accuracy: 0.7051\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7922 - val_loss: 0.9727 - val_accuracy: 0.7051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7950 - val_loss: 0.9713 - val_accuracy: 0.7051\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.7950 - val_loss: 0.9699 - val_accuracy: 0.7051\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7950 - val_loss: 0.9614 - val_accuracy: 0.7051\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7950 - val_loss: 0.9612 - val_accuracy: 0.7051\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7978 - val_loss: 0.9438 - val_accuracy: 0.6987\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8006 - val_loss: 0.9371 - val_accuracy: 0.6987\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8006 - val_loss: 0.9493 - val_accuracy: 0.6987\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8033 - val_loss: 0.9309 - val_accuracy: 0.6987\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8061 - val_loss: 0.9311 - val_accuracy: 0.6987\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8033 - val_loss: 0.9397 - val_accuracy: 0.6987\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8089 - val_loss: 0.9128 - val_accuracy: 0.7115\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8089 - val_loss: 0.9244 - val_accuracy: 0.6987\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8061 - val_loss: 0.9313 - val_accuracy: 0.6987\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8089 - val_loss: 0.9159 - val_accuracy: 0.7115\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8089 - val_loss: 0.9165 - val_accuracy: 0.7115\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8144 - val_loss: 0.9076 - val_accuracy: 0.7115\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8283 - val_loss: 0.9001 - val_accuracy: 0.7179\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8172 - val_loss: 0.9152 - val_accuracy: 0.7115\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8116 - val_loss: 0.9106 - val_accuracy: 0.7115\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8144 - val_loss: 0.9066 - val_accuracy: 0.7115\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8144 - val_loss: 0.9080 - val_accuracy: 0.7115\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8172 - val_loss: 0.8958 - val_accuracy: 0.7372\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8172 - val_loss: 0.9746 - val_accuracy: 0.7179\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8172 - val_loss: 0.9699 - val_accuracy: 0.7244\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8199 - val_loss: 0.9661 - val_accuracy: 0.7372\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8172 - val_loss: 0.9641 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8199 - val_loss: 0.9603 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8227 - val_loss: 0.9590 - val_accuracy: 0.7564\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8199 - val_loss: 0.9580 - val_accuracy: 0.7564\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8255 - val_loss: 0.9533 - val_accuracy: 0.7564\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8283 - val_loss: 0.9516 - val_accuracy: 0.7564\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8199 - val_loss: 0.9498 - val_accuracy: 0.7564\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8283 - val_loss: 0.9480 - val_accuracy: 0.7692\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8255 - val_loss: 0.9462 - val_accuracy: 0.7692\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8283 - val_loss: 0.9424 - val_accuracy: 0.7756\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3359 - accuracy: 0.8283 - val_loss: 0.9402 - val_accuracy: 0.7756\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.8310 - val_loss: 0.9389 - val_accuracy: 0.7692\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8421 - val_loss: 0.9388 - val_accuracy: 0.7821\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3310 - accuracy: 0.8338 - val_loss: 0.9325 - val_accuracy: 0.7756\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8283 - val_loss: 0.9288 - val_accuracy: 0.7756\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8310 - val_loss: 0.9259 - val_accuracy: 0.7692\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8366 - val_loss: 0.9243 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253f482a308>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:40:45.155756Z",
     "start_time": "2021-08-10T13:40:44.892827Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzLcwktjsL2B",
    "outputId": "17a14e53-d467-4835-caee-19cbb197eca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.8162\n",
      "accuracy: 81.62%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRBzHPilsYSk"
   },
   "source": [
    "**Iteration 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:41:03.236006Z",
     "start_time": "2021-08-10T13:40:47.979176Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V7vzzYseSH",
    "outputId": "8afb9edd-d4dd-4812-ea6a-0f7d6c5e6976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 3.7829 - accuracy: 0.6233 - val_loss: 4.3357 - val_accuracy: 0.5513\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.5487 - accuracy: 0.6316 - val_loss: 4.2949 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.3524 - accuracy: 0.6565 - val_loss: 4.1918 - val_accuracy: 0.5641\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.1303 - accuracy: 0.6620 - val_loss: 4.1651 - val_accuracy: 0.5641\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.0482 - accuracy: 0.6676 - val_loss: 4.1509 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.9487 - accuracy: 0.6814 - val_loss: 4.2152 - val_accuracy: 0.6218\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.9290 - accuracy: 0.6842 - val_loss: 4.1424 - val_accuracy: 0.6218\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.9205 - accuracy: 0.6870 - val_loss: 4.1306 - val_accuracy: 0.6282\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.9153 - accuracy: 0.6925 - val_loss: 4.0578 - val_accuracy: 0.6282\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.9115 - accuracy: 0.6953 - val_loss: 4.0575 - val_accuracy: 0.6218\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.8847 - accuracy: 0.7008 - val_loss: 3.9596 - val_accuracy: 0.6154\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.7390 - accuracy: 0.6898 - val_loss: 3.8672 - val_accuracy: 0.5897\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.7211 - accuracy: 0.6925 - val_loss: 3.8629 - val_accuracy: 0.5962\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.7167 - accuracy: 0.6925 - val_loss: 3.8650 - val_accuracy: 0.6026\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.7125 - accuracy: 0.7036 - val_loss: 3.8778 - val_accuracy: 0.6026\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.6397 - accuracy: 0.7091 - val_loss: 3.9351 - val_accuracy: 0.6090\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.6281 - accuracy: 0.7230 - val_loss: 3.9356 - val_accuracy: 0.6218\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.6232 - accuracy: 0.7230 - val_loss: 3.9345 - val_accuracy: 0.6282\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5872 - accuracy: 0.7285 - val_loss: 3.9302 - val_accuracy: 0.6218\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5778 - accuracy: 0.7285 - val_loss: 3.8077 - val_accuracy: 0.6282\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5746 - accuracy: 0.7313 - val_loss: 3.7874 - val_accuracy: 0.6282\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5421 - accuracy: 0.7396 - val_loss: 3.7567 - val_accuracy: 0.6346\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.3767 - accuracy: 0.7341 - val_loss: 3.8238 - val_accuracy: 0.6538\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.1676 - accuracy: 0.7424 - val_loss: 3.7429 - val_accuracy: 0.6603\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0872 - accuracy: 0.7424 - val_loss: 3.7209 - val_accuracy: 0.6603\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0314 - accuracy: 0.7452 - val_loss: 3.7166 - val_accuracy: 0.6603\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0240 - accuracy: 0.7452 - val_loss: 3.7146 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2.0198 - accuracy: 0.7507 - val_loss: 3.7130 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.9851 - accuracy: 0.7535 - val_loss: 3.6396 - val_accuracy: 0.6603\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.8852 - accuracy: 0.7562 - val_loss: 3.4949 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.8341 - accuracy: 0.7535 - val_loss: 3.3449 - val_accuracy: 0.6603\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.5649 - accuracy: 0.7507 - val_loss: 2.9729 - val_accuracy: 0.6346\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.4973 - accuracy: 0.7479 - val_loss: 2.6141 - val_accuracy: 0.6346\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.4890 - accuracy: 0.7535 - val_loss: 2.5268 - val_accuracy: 0.6346\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4843 - accuracy: 0.7535 - val_loss: 2.5229 - val_accuracy: 0.6410\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.4792 - accuracy: 0.7590 - val_loss: 2.5098 - val_accuracy: 0.6474\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4747 - accuracy: 0.7590 - val_loss: 2.5059 - val_accuracy: 0.6474\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4708 - accuracy: 0.7590 - val_loss: 2.5023 - val_accuracy: 0.6474\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4405 - accuracy: 0.7701 - val_loss: 2.5410 - val_accuracy: 0.6538\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4062 - accuracy: 0.7701 - val_loss: 2.4477 - val_accuracy: 0.6538\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2825 - accuracy: 0.7618 - val_loss: 2.0961 - val_accuracy: 0.6154\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.2499 - accuracy: 0.7784 - val_loss: 2.0974 - val_accuracy: 0.6346\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.0915 - accuracy: 0.7867 - val_loss: 1.5343 - val_accuracy: 0.5962\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9599 - accuracy: 0.7673 - val_loss: 1.5097 - val_accuracy: 0.6026\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.9506 - accuracy: 0.7756 - val_loss: 1.5045 - val_accuracy: 0.6090\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.9426 - accuracy: 0.7839 - val_loss: 1.5005 - val_accuracy: 0.6346\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.9361 - accuracy: 0.7867 - val_loss: 1.5011 - val_accuracy: 0.6410\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.9310 - accuracy: 0.7867 - val_loss: 1.5037 - val_accuracy: 0.6474\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.9265 - accuracy: 0.7867 - val_loss: 1.5083 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.8988 - accuracy: 0.7895 - val_loss: 1.5687 - val_accuracy: 0.6923\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.8828 - accuracy: 0.7950 - val_loss: 1.6457 - val_accuracy: 0.7179\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8822 - accuracy: 0.7922 - val_loss: 1.6384 - val_accuracy: 0.7179\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8766 - accuracy: 0.7950 - val_loss: 1.6303 - val_accuracy: 0.7179\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8737 - accuracy: 0.8006 - val_loss: 1.6281 - val_accuracy: 0.7179\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8703 - accuracy: 0.7978 - val_loss: 1.5798 - val_accuracy: 0.7115\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8675 - accuracy: 0.7950 - val_loss: 1.5729 - val_accuracy: 0.7115\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8647 - accuracy: 0.7978 - val_loss: 1.5666 - val_accuracy: 0.7051\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.8617 - accuracy: 0.8006 - val_loss: 1.5005 - val_accuracy: 0.6987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8346 - accuracy: 0.8061 - val_loss: 1.3064 - val_accuracy: 0.6795\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7507 - accuracy: 0.8061 - val_loss: 1.2274 - val_accuracy: 0.6731\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7473 - accuracy: 0.8089 - val_loss: 1.3124 - val_accuracy: 0.6795\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7433 - accuracy: 0.8144 - val_loss: 1.3993 - val_accuracy: 0.6795\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7401 - accuracy: 0.8172 - val_loss: 1.5009 - val_accuracy: 0.6859\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7376 - accuracy: 0.8172 - val_loss: 1.4999 - val_accuracy: 0.6859\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7352 - accuracy: 0.8089 - val_loss: 1.4988 - val_accuracy: 0.6859\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7331 - accuracy: 0.8061 - val_loss: 1.3178 - val_accuracy: 0.6795\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7313 - accuracy: 0.8033 - val_loss: 1.3243 - val_accuracy: 0.6795\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.8061 - val_loss: 1.3356 - val_accuracy: 0.6795\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7264 - accuracy: 0.8061 - val_loss: 1.4380 - val_accuracy: 0.6795\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7245 - accuracy: 0.8089 - val_loss: 1.4955 - val_accuracy: 0.6859\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7221 - accuracy: 0.8089 - val_loss: 1.4943 - val_accuracy: 0.6859\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7203 - accuracy: 0.8089 - val_loss: 1.4935 - val_accuracy: 0.6859\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7181 - accuracy: 0.8089 - val_loss: 1.4925 - val_accuracy: 0.6859\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7166 - accuracy: 0.8089 - val_loss: 1.4919 - val_accuracy: 0.6795\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7150 - accuracy: 0.8116 - val_loss: 1.4913 - val_accuracy: 0.6731\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7128 - accuracy: 0.8089 - val_loss: 1.4920 - val_accuracy: 0.6795\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7106 - accuracy: 0.8089 - val_loss: 1.4918 - val_accuracy: 0.6731\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.8089 - val_loss: 1.4946 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7069 - accuracy: 0.8089 - val_loss: 1.4955 - val_accuracy: 0.6731\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7041 - accuracy: 0.8116 - val_loss: 1.4912 - val_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.8089 - val_loss: 1.4914 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.8089 - val_loss: 1.4954 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.8089 - val_loss: 1.4945 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.8116 - val_loss: 1.4872 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.8089 - val_loss: 1.5672 - val_accuracy: 0.6859\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.8172 - val_loss: 1.5685 - val_accuracy: 0.6923\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.8199 - val_loss: 1.5244 - val_accuracy: 0.6923\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.8227 - val_loss: 1.5222 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.8227 - val_loss: 1.5164 - val_accuracy: 0.6795\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.8199 - val_loss: 1.5169 - val_accuracy: 0.6859\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.8199 - val_loss: 1.5143 - val_accuracy: 0.6795\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.8227 - val_loss: 1.4988 - val_accuracy: 0.6859\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.8283 - val_loss: 1.4985 - val_accuracy: 0.6859\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.8310 - val_loss: 1.4167 - val_accuracy: 0.6923\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.8310 - val_loss: 1.4241 - val_accuracy: 0.6923\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.8310 - val_loss: 1.4280 - val_accuracy: 0.6923\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8310 - val_loss: 1.4333 - val_accuracy: 0.6923\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.8421 - val_loss: 1.4124 - val_accuracy: 0.6859\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.8393 - val_loss: 1.4221 - val_accuracy: 0.6923\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.8421 - val_loss: 1.4252 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253f49bd788>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:41:03.401704Z",
     "start_time": "2021-08-10T13:41:03.241019Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEsR6LX7siDU",
    "outputId": "8feb7e78-e0b0-4341-e0ad-208a296d7680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.8680 - accuracy: 0.8008\n",
      "accuracy: 80.08%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgKCVuPSszB5"
   },
   "source": [
    "**Iteration 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:41:36.449676Z",
     "start_time": "2021-08-10T13:41:05.454345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkOmR6ZAstv4",
    "outputId": "e9001bfa-8a84-4443-9736-6e30e02c986e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - ETA: 0s - loss: 3.1278 - accuracy: 0.6787WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 3.1278 - accuracy: 0.6787 - val_loss: 3.9715 - val_accuracy: 0.6410\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.9195 - accuracy: 0.7036 - val_loss: 3.9497 - val_accuracy: 0.6410\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.6998 - accuracy: 0.7202 - val_loss: 3.9264 - val_accuracy: 0.6474\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.4931 - accuracy: 0.7313 - val_loss: 3.8303 - val_accuracy: 0.6667\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.3935 - accuracy: 0.7424 - val_loss: 3.7582 - val_accuracy: 0.6603\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.3417 - accuracy: 0.7479 - val_loss: 3.8338 - val_accuracy: 0.6667\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.1392 - accuracy: 0.7673 - val_loss: 3.8478 - val_accuracy: 0.6667\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.1529 - accuracy: 0.7673 - val_loss: 3.8247 - val_accuracy: 0.6667\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.1100 - accuracy: 0.7673 - val_loss: 3.8465 - val_accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.0269 - accuracy: 0.7618 - val_loss: 3.9043 - val_accuracy: 0.6603\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.0158 - accuracy: 0.7701 - val_loss: 3.9018 - val_accuracy: 0.6731\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9152 - accuracy: 0.7756 - val_loss: 3.9032 - val_accuracy: 0.6923\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.7246 - accuracy: 0.7784 - val_loss: 3.8458 - val_accuracy: 0.6859\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.6566 - accuracy: 0.7812 - val_loss: 3.7100 - val_accuracy: 0.6859\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6496 - accuracy: 0.7784 - val_loss: 3.7522 - val_accuracy: 0.6859\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6457 - accuracy: 0.7867 - val_loss: 3.6793 - val_accuracy: 0.6859\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6410 - accuracy: 0.7895 - val_loss: 3.5981 - val_accuracy: 0.6859\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6362 - accuracy: 0.7867 - val_loss: 3.6727 - val_accuracy: 0.6795\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6323 - accuracy: 0.7950 - val_loss: 3.5871 - val_accuracy: 0.6795\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6278 - accuracy: 0.8006 - val_loss: 3.5740 - val_accuracy: 0.6795\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6253 - accuracy: 0.7978 - val_loss: 3.5790 - val_accuracy: 0.6795\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6220 - accuracy: 0.8033 - val_loss: 3.5763 - val_accuracy: 0.6859\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6199 - accuracy: 0.8061 - val_loss: 3.5890 - val_accuracy: 0.6859\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6259 - accuracy: 0.8033 - val_loss: 3.5645 - val_accuracy: 0.6859\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5919 - accuracy: 0.8116 - val_loss: 3.5416 - val_accuracy: 0.6923\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3781 - accuracy: 0.7950 - val_loss: 3.3687 - val_accuracy: 0.6987\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2932 - accuracy: 0.8310 - val_loss: 3.4622 - val_accuracy: 0.6923\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2546 - accuracy: 0.8310 - val_loss: 3.5194 - val_accuracy: 0.6987\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.8283 - val_loss: 3.0547 - val_accuracy: 0.7051\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.7743 - accuracy: 0.7479 - val_loss: 3.0519 - val_accuracy: 0.6859\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.7307 - accuracy: 0.7922 - val_loss: 2.9904 - val_accuracy: 0.6923\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.7136 - accuracy: 0.8006 - val_loss: 3.0111 - val_accuracy: 0.6923\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.7053 - accuracy: 0.8033 - val_loss: 3.0106 - val_accuracy: 0.6987\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6994 - accuracy: 0.8199 - val_loss: 3.0245 - val_accuracy: 0.6987\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6924 - accuracy: 0.8227 - val_loss: 3.0064 - val_accuracy: 0.7051\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6887 - accuracy: 0.8199 - val_loss: 3.0060 - val_accuracy: 0.7051\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6860 - accuracy: 0.8227 - val_loss: 3.0017 - val_accuracy: 0.7051\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6840 - accuracy: 0.8172 - val_loss: 2.9258 - val_accuracy: 0.6987\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6811 - accuracy: 0.8227 - val_loss: 2.9144 - val_accuracy: 0.6987\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6789 - accuracy: 0.8199 - val_loss: 2.9185 - val_accuracy: 0.7115\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6749 - accuracy: 0.8255 - val_loss: 2.9074 - val_accuracy: 0.6987\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6739 - accuracy: 0.8227 - val_loss: 2.9106 - val_accuracy: 0.7115\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6368 - accuracy: 0.8310 - val_loss: 2.9034 - val_accuracy: 0.7051\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6281 - accuracy: 0.8338 - val_loss: 2.8973 - val_accuracy: 0.7051\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.6245 - accuracy: 0.8310 - val_loss: 2.8989 - val_accuracy: 0.7051\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6234 - accuracy: 0.8366 - val_loss: 2.9012 - val_accuracy: 0.7051\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6207 - accuracy: 0.8310 - val_loss: 2.9035 - val_accuracy: 0.7051\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.6168 - accuracy: 0.8310 - val_loss: 2.8997 - val_accuracy: 0.7051\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6148 - accuracy: 0.8338 - val_loss: 2.8991 - val_accuracy: 0.7051\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6134 - accuracy: 0.8366 - val_loss: 2.8996 - val_accuracy: 0.7051\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6109 - accuracy: 0.8366 - val_loss: 2.8987 - val_accuracy: 0.7051\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6090 - accuracy: 0.8338 - val_loss: 2.8987 - val_accuracy: 0.7051\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6072 - accuracy: 0.8421 - val_loss: 2.9007 - val_accuracy: 0.7051\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.6055 - accuracy: 0.8366 - val_loss: 2.9018 - val_accuracy: 0.7051\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6043 - accuracy: 0.8366 - val_loss: 2.8162 - val_accuracy: 0.7051\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6036 - accuracy: 0.8338 - val_loss: 2.7611 - val_accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6015 - accuracy: 0.8393 - val_loss: 2.7515 - val_accuracy: 0.7115\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5990 - accuracy: 0.8421 - val_loss: 2.7447 - val_accuracy: 0.7115\n",
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5976 - accuracy: 0.8393 - val_loss: 2.7506 - val_accuracy: 0.7115\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5968 - accuracy: 0.8366 - val_loss: 2.6871 - val_accuracy: 0.7115\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5947 - accuracy: 0.8366 - val_loss: 2.7290 - val_accuracy: 0.7179\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5946 - accuracy: 0.8366 - val_loss: 2.6556 - val_accuracy: 0.7244\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5915 - accuracy: 0.8393 - val_loss: 2.6437 - val_accuracy: 0.7244\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5898 - accuracy: 0.8366 - val_loss: 2.6388 - val_accuracy: 0.7244\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5904 - accuracy: 0.8338 - val_loss: 2.6427 - val_accuracy: 0.7244\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5950 - accuracy: 0.8393 - val_loss: 2.6293 - val_accuracy: 0.7244\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5918 - accuracy: 0.8338 - val_loss: 2.6438 - val_accuracy: 0.7244\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5858 - accuracy: 0.8366 - val_loss: 2.6372 - val_accuracy: 0.7244\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5850 - accuracy: 0.8366 - val_loss: 2.6405 - val_accuracy: 0.7244\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5842 - accuracy: 0.8366 - val_loss: 2.6364 - val_accuracy: 0.7179\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5839 - accuracy: 0.8366 - val_loss: 2.6217 - val_accuracy: 0.7179\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5811 - accuracy: 0.8449 - val_loss: 2.6325 - val_accuracy: 0.7179\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.5805 - accuracy: 0.8449 - val_loss: 2.6226 - val_accuracy: 0.7179\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5864 - accuracy: 0.8449 - val_loss: 2.5371 - val_accuracy: 0.7179\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5797 - accuracy: 0.8476 - val_loss: 2.6278 - val_accuracy: 0.7244\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5751 - accuracy: 0.8393 - val_loss: 2.7101 - val_accuracy: 0.7244\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5756 - accuracy: 0.8393 - val_loss: 2.7027 - val_accuracy: 0.7308\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5723 - accuracy: 0.8449 - val_loss: 2.7058 - val_accuracy: 0.7244\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5727 - accuracy: 0.8421 - val_loss: 2.7063 - val_accuracy: 0.7308\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.5700 - accuracy: 0.8449 - val_loss: 2.7001 - val_accuracy: 0.7308\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.4829 - accuracy: 0.8421 - val_loss: 2.3213 - val_accuracy: 0.7115\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4721 - accuracy: 0.8421 - val_loss: 2.4322 - val_accuracy: 0.7179\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4539 - accuracy: 0.8560 - val_loss: 2.6318 - val_accuracy: 0.7244\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4447 - accuracy: 0.8560 - val_loss: 2.3944 - val_accuracy: 0.7244\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4425 - accuracy: 0.8532 - val_loss: 2.3343 - val_accuracy: 0.7179\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4403 - accuracy: 0.8560 - val_loss: 2.3225 - val_accuracy: 0.7179\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4381 - accuracy: 0.8587 - val_loss: 2.2526 - val_accuracy: 0.7179\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4363 - accuracy: 0.8560 - val_loss: 2.3212 - val_accuracy: 0.7308\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4344 - accuracy: 0.8587 - val_loss: 2.3789 - val_accuracy: 0.7308\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4345 - accuracy: 0.8560 - val_loss: 2.2991 - val_accuracy: 0.7179\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.4333 - accuracy: 0.8560 - val_loss: 2.3082 - val_accuracy: 0.7179\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4310 - accuracy: 0.8532 - val_loss: 2.2963 - val_accuracy: 0.7179\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4298 - accuracy: 0.8560 - val_loss: 2.3002 - val_accuracy: 0.7179\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.4273 - accuracy: 0.8532 - val_loss: 2.3219 - val_accuracy: 0.7179\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4274 - accuracy: 0.8560 - val_loss: 2.2900 - val_accuracy: 0.7179\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4270 - accuracy: 0.8476 - val_loss: 2.3810 - val_accuracy: 0.7372\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4260 - accuracy: 0.8587 - val_loss: 2.4531 - val_accuracy: 0.7308\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4243 - accuracy: 0.8615 - val_loss: 2.3725 - val_accuracy: 0.7372\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4230 - accuracy: 0.8587 - val_loss: 2.3679 - val_accuracy: 0.7372\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4258 - accuracy: 0.8587 - val_loss: 2.4086 - val_accuracy: 0.7372\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4222 - accuracy: 0.8615 - val_loss: 2.3848 - val_accuracy: 0.7372\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4203 - accuracy: 0.8532 - val_loss: 2.4302 - val_accuracy: 0.7372\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.4176 - accuracy: 0.8560 - val_loss: 2.4359 - val_accuracy: 0.7372\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4209 - accuracy: 0.8643 - val_loss: 2.4253 - val_accuracy: 0.7436\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4189 - accuracy: 0.8643 - val_loss: 2.4360 - val_accuracy: 0.7372\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4153 - accuracy: 0.8670 - val_loss: 2.4347 - val_accuracy: 0.7436\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4143 - accuracy: 0.8587 - val_loss: 2.4435 - val_accuracy: 0.7436\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4142 - accuracy: 0.8698 - val_loss: 2.4224 - val_accuracy: 0.7436\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4114 - accuracy: 0.8615 - val_loss: 2.4395 - val_accuracy: 0.7436\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4124 - accuracy: 0.8615 - val_loss: 2.5089 - val_accuracy: 0.7436\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4102 - accuracy: 0.8587 - val_loss: 2.4223 - val_accuracy: 0.7436\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4095 - accuracy: 0.8670 - val_loss: 2.4313 - val_accuracy: 0.7372\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4072 - accuracy: 0.8643 - val_loss: 2.3655 - val_accuracy: 0.7372\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4070 - accuracy: 0.8698 - val_loss: 2.4251 - val_accuracy: 0.7436\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4077 - accuracy: 0.8698 - val_loss: 2.4187 - val_accuracy: 0.7436\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4046 - accuracy: 0.8698 - val_loss: 2.3337 - val_accuracy: 0.7436\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4028 - accuracy: 0.8698 - val_loss: 2.3267 - val_accuracy: 0.7436\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4046 - accuracy: 0.8809 - val_loss: 2.3210 - val_accuracy: 0.7500\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4031 - accuracy: 0.8753 - val_loss: 2.3970 - val_accuracy: 0.7436\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4006 - accuracy: 0.8781 - val_loss: 2.4256 - val_accuracy: 0.7564\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.4008 - accuracy: 0.8837 - val_loss: 2.4043 - val_accuracy: 0.7628\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3983 - accuracy: 0.8753 - val_loss: 2.3996 - val_accuracy: 0.7564\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3974 - accuracy: 0.8837 - val_loss: 2.4007 - val_accuracy: 0.7628\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3972 - accuracy: 0.8809 - val_loss: 2.3986 - val_accuracy: 0.7628\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3953 - accuracy: 0.8920 - val_loss: 2.4025 - val_accuracy: 0.7564\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3954 - accuracy: 0.8837 - val_loss: 2.4748 - val_accuracy: 0.7564\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3944 - accuracy: 0.8781 - val_loss: 2.4105 - val_accuracy: 0.7564\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3916 - accuracy: 0.8920 - val_loss: 2.3384 - val_accuracy: 0.7564\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3921 - accuracy: 0.8864 - val_loss: 2.4061 - val_accuracy: 0.7564\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3934 - accuracy: 0.8837 - val_loss: 2.3209 - val_accuracy: 0.7628\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.8864 - val_loss: 2.5435 - val_accuracy: 0.7564\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3902 - accuracy: 0.8892 - val_loss: 2.3235 - val_accuracy: 0.7628\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3948 - accuracy: 0.8920 - val_loss: 2.4680 - val_accuracy: 0.7692\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3871 - accuracy: 0.8947 - val_loss: 2.3908 - val_accuracy: 0.7628\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3866 - accuracy: 0.8920 - val_loss: 2.3969 - val_accuracy: 0.7564\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3850 - accuracy: 0.8920 - val_loss: 2.4619 - val_accuracy: 0.7628\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3851 - accuracy: 0.8892 - val_loss: 2.4646 - val_accuracy: 0.7628\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3827 - accuracy: 0.8920 - val_loss: 2.4508 - val_accuracy: 0.7692\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3813 - accuracy: 0.8947 - val_loss: 2.4668 - val_accuracy: 0.7628\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3936 - accuracy: 0.8920 - val_loss: 2.3203 - val_accuracy: 0.7628\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3808 - accuracy: 0.8920 - val_loss: 2.3790 - val_accuracy: 0.7692\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3941 - accuracy: 0.8947 - val_loss: 2.3665 - val_accuracy: 0.7821\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.3810 - accuracy: 0.8947 - val_loss: 2.4376 - val_accuracy: 0.7821\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3784 - accuracy: 0.8975 - val_loss: 2.3721 - val_accuracy: 0.7821\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3765 - accuracy: 0.8975 - val_loss: 2.3669 - val_accuracy: 0.7821\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3745 - accuracy: 0.8975 - val_loss: 2.3702 - val_accuracy: 0.7821\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.3754 - accuracy: 0.8975 - val_loss: 2.4338 - val_accuracy: 0.7821\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3750 - accuracy: 0.8975 - val_loss: 2.2985 - val_accuracy: 0.7821\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3791 - accuracy: 0.8892 - val_loss: 2.5266 - val_accuracy: 0.7692\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3747 - accuracy: 0.8947 - val_loss: 2.3750 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253f5f8e188>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T13:41:36.690624Z",
     "start_time": "2021-08-10T13:41:36.459665Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU7rVoLhtCUo",
    "outputId": "826a0616-345d-4e52-e41b-c94d3e63c62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 1.6719 - accuracy: 0.8646\n",
      "accuracy: 86.46%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HLFn6wCtL20"
   },
   "source": [
    "# Getting Best Accuracy with Iteration 1 accuracy: 91.88% out of all 4 iterations.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMXM1iFY5ncSkwhqhOYGuyB",
   "include_colab_link": true,
   "name": "Assign_Neural_Network_Forest_Fire.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
